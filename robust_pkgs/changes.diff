diff -ruN /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/train.py /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/train.py
--- /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/train.py	2022-06-08 10:26:18.000000000 +0800
+++ /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/train.py	2024-03-31 13:15:12.854606858 +0800
@@ -321,10 +321,9 @@
             pbar = tqdm(pbar, total=nb, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')  # progress bar
         optimizer.zero_grad()
         for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------
-            callbacks.run('on_train_batch_start')
             ni = i + nb * epoch  # number integrated batches (since train start)
             imgs = imgs.to(device, non_blocking=True).float() / 255  # uint8 to float32, 0-255 to 0.0-1.0
-
+            callbacks.run('on_train_batch_start', model, imgs, targets, device)
             # Warmup
             if ni <= nw:
                 xi = [0, nw]  # x interp
diff -ruN ./ultralytics-yolov5-0.1.1/yolov5/utils/dataloaders.py /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/dataloaders.py
--- /yolov5/utils/dataloaders.py	2022-06-08 09:57:38.000000000 +0800
+++ /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/dataloaders.py	2024-03-23 10:45:11.212443094 +0800
@@ -468,7 +468,7 @@
         self.im_files = list(cache.keys())  # update
         self.label_files = img2label_paths(cache.keys())  # update
         n = len(shapes)  # number of images
-        bi = np.floor(np.arange(n) / batch_size).astype(np.int)  # batch index
+        bi = np.floor(np.arange(n) / batch_size).astype(int)  # batch index
         nb = bi[-1] + 1  # number of batches
         self.batch = bi  # batch index of image
         self.n = n
@@ -510,7 +510,7 @@
                 elif mini > 1:
                     shapes[i] = [1, 1 / mini]
 
-            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(np.int) * stride
+            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(int) * stride
 
         # Cache images into RAM/disk for faster training (WARNING: large datasets may exceed system resources)
         self.ims = [None] * n
@@ -886,7 +886,7 @@
                     b = x[1:] * [w, h, w, h]  # box
                     # b[2:] = b[2:].max()  # rectangle to square
                     b[2:] = b[2:] * 1.2 + 3  # pad
-                    b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(np.int)
+                    b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(int)
 
                     b[[0, 2]] = np.clip(b[[0, 2]], 0, w)  # clip boxes outside of image
                     b[[1, 3]] = np.clip(b[[1, 3]], 0, h)
diff -ruN /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/general.py /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/general.py
--- /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/general.py	2022-06-08 10:28:32.000000000 +0800
+++ /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/general.py	2024-04-02 16:13:55.769931979 +0800
@@ -83,16 +83,17 @@
 def set_logging(name=None, verbose=VERBOSE):
     # Sets level and returns logger
     if is_kaggle():
-        for h in logging.root.handlers:
+        for h in logging.root.handlers[:]:  # make a copy of the list
             logging.root.removeHandler(h)  # remove all handlers associated with the root logger object
     rank = int(os.getenv('RANK', -1))  # rank in world for Multi-GPU trainings
     level = logging.INFO if verbose and rank in {-1, 0} else logging.WARNING
     log = logging.getLogger(name)
     log.setLevel(level)
-    handler = logging.StreamHandler()
-    handler.setFormatter(logging.Formatter("%(message)s"))
-    handler.setLevel(level)
-    log.addHandler(handler)
+    if not log.handlers:  # only add handler if there is no handler yet
+        handler = logging.StreamHandler()
+        handler.setFormatter(logging.Formatter("%(message)s"))
+        handler.setLevel(level)
+        log.addHandler(handler)
 
 
 set_logging()  # run before defining LOGGER
@@ -501,7 +502,7 @@
             dt = f'({round(time.time() - t, 1)}s)'
             s = f"success ✅ {dt}, saved to {colorstr('bold', root)}" if r in (0, None) else f"failure {dt} ❌"
             LOGGER.info(emojis(f"Dataset download {s}"))
-    check_font('Arial.ttf' if is_ascii(data['names']) else 'Arial.Unicode.ttf', progress=True)  # download fonts
+    # check_font('Arial.ttf' if is_ascii(data['names']) else 'Arial.Unicode.ttf', progress=True)  # download fonts
     return data  # dictionary
 
 
@@ -634,7 +635,7 @@
         return torch.Tensor()
 
     labels = np.concatenate(labels, 0)  # labels.shape = (866643, 5) for COCO
-    classes = labels[:, 0].astype(np.int)  # labels = [class xywh]
+    classes = labels[:, 0].astype(int)  # labels = [class xywh]
     weights = np.bincount(classes, minlength=nc)  # occurrences per class
 
     # Prepend gridpoint count (for uCE training)
@@ -650,7 +651,7 @@
 def labels_to_image_weights(labels, nc=80, class_weights=np.ones(80)):
     # Produces image weights based on class_weights and image contents
     # Usage: index = random.choices(range(n), weights=image_weights, k=1)  # weighted image sample
-    class_counts = np.array([np.bincount(x[:, 0].astype(np.int), minlength=nc) for x in labels])
+    class_counts = np.array([np.bincount(x[:, 0].astype(int), minlength=nc) for x in labels])
     return (class_weights.reshape(1, nc) * class_counts).sum(1)
 
 
@@ -738,7 +739,7 @@
     for i, s in enumerate(segments):
         x = np.linspace(0, len(s) - 1, n)
         xp = np.arange(len(s))
-        segments[i] = np.concatenate([np.interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # segment xy
+        segments[i] = np.concatenate([interp(x, xp, s[:, i]) for i in range(2)]).reshape(2, -1).T  # segment xy
     return segments
 
 
@@ -796,7 +797,7 @@
     # min_wh = 2  # (pixels) minimum box width and height
     max_wh = 7680  # (pixels) maximum box width and height
     max_nms = 30000  # maximum number of boxes into torchvision.ops.nms()
-    time_limit = 0.3 + 0.03 * bs  # seconds to quit after
+    time_limit = 30 + 0.03 * bs  # seconds to quit after
     redundant = True  # require redundant detections
     multi_label &= nc > 1  # multiple labels per box (adds 0.5ms/img)
     merge = False  # use merge-NMS
diff -ruN /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/loss.py /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/loss.py
--- /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/loss.py	2022-06-07 09:28:50.000000000 +0800
+++ /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/utils/loss.py	2024-04-07 10:35:37.799444693 +0800
@@ -194,7 +194,7 @@
             device=self.device).float() * g  # offsets
 
         for i in range(self.nl):
-            anchors = self.anchors[i]
+            anchors, shape = self.anchors[i], p[i].shape
             gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain
 
             # Match targets to anchors
@@ -225,7 +225,7 @@
             gi, gj = gij.T  # grid indices
 
             # Append
-            indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # image, anchor, grid indices
+            indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1)))
             tbox.append(torch.cat((gxy - gij, gwh), 1))  # box
             anch.append(anchors[a])  # anchors
             tcls.append(c)  # class
diff -ruN /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/val.py /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/val.py
--- /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/val.py	2022-06-08 10:29:25.000000000 +0800
+++ /root/anaconda3/envs/py39/lib/python3.9/site-packages/yolov5/val.py	2024-04-06 00:00:52.390615710 +0800
@@ -192,13 +192,13 @@
     callbacks.run('on_val_start')
     pbar = tqdm(dataloader, desc=s, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')  # progress bar
     for batch_i, (im, targets, paths, shapes) in enumerate(pbar):
-        callbacks.run('on_val_batch_start')
         t1 = time_sync()
         if cuda:
             im = im.to(device, non_blocking=True)
             targets = targets.to(device)
         im = im.half() if half else im.float()  # uint8 to fp16/32
         im /= 255  # 0 - 255 to 0.0 - 1.0
+        callbacks.run('on_val_batch_start', model, im, targets, device, shapes)
         nb, _, height, width = im.shape  # batch size, channels, height, width
         t2 = time_sync()
         dt[0] += t2 - t1
